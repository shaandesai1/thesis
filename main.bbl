\begin{thebibliography}{10}

\bibitem{atkinson_bayesian_2020}
S.~Atkinson.
\newblock Bayesian {Hidden} {Physics} {Models}: {Uncertainty} {Quantification}
  for {Discovery} of {Nonlinear} {Partial} {Differential} {Operators} from
  {Data}.
\newblock {\em arXiv:2006.04228 [cs, stat]}, June 2020.
\newblock arXiv: 2006.04228.

\bibitem{bapst_unveiling_2020}
V.~Bapst, T.~Keck, A.~Grabska-Barwińska, C.~Donner, E.~D. Cubuk, S.~S.
  Schoenholz, A.~Obika, A.~W.~R. Nelson, T.~Back, D.~Hassabis, and P.~Kohli.
\newblock Unveiling the predictive power of static structure in glassy systems.
\newblock {\em Nature Physics}, 16(4):448--454, Apr. 2020.
\newblock Number: 4 Publisher: Nature Publishing Group.

\bibitem{battaglia_relational_2018}
P.~W. Battaglia, J.~B. Hamrick, V.~Bapst, A.~Sanchez-Gonzalez, V.~Zambaldi,
  M.~Malinowski, A.~Tacchetti, D.~Raposo, A.~Santoro, R.~Faulkner, C.~Gulcehre,
  F.~Song, A.~Ballard, J.~Gilmer, G.~Dahl, A.~Vaswani, K.~Allen, C.~Nash,
  V.~Langston, C.~Dyer, N.~Heess, D.~Wierstra, P.~Kohli, M.~Botvinick,
  O.~Vinyals, Y.~Li, and R.~Pascanu.
\newblock Relational inductive biases, deep learning, and graph networks.
\newblock {\em arXiv:1806.01261 [cs, stat]}, Oct. 2018.
\newblock arXiv: 1806.01261.

\bibitem{battaglia_interaction_2016}
P.~W. Battaglia, R.~Pascanu, M.~Lai, D.~Rezende, and K.~Kavukcuoglu.
\newblock Interaction {Networks} for {Learning} about {Objects}, {Relations}
  and {Physics}.
\newblock {\em arXiv:1612.00222 [cs]}, Dec. 2016.
\newblock arXiv: 1612.00222.

\bibitem{brunton_discovering_2016}
S.~L. Brunton, J.~L. Proctor, and J.~N. Kutz.
\newblock Discovering governing equations from data by sparse identification of
  nonlinear dynamical systems.
\newblock {\em Proceedings of the National Academy of Sciences},
  113(15):3932--3937, Apr. 2016.

\bibitem{chang_reversible_2017}
B.~Chang, L.~Meng, E.~Haber, L.~Ruthotto, D.~Begert, and E.~Holtham.
\newblock Reversible {Architectures} for {Arbitrarily} {Deep} {Residual}
  {Neural} {Networks}.
\newblock {\em arXiv:1709.03698 [cs, stat]}, Nov. 2017.
\newblock arXiv: 1709.03698.

\bibitem{chen_neural_2018}
R.~T.~Q. Chen, Y.~Rubanova, J.~Bettencourt, and D.~K. Duvenaud.
\newblock Neural {Ordinary} {Differential} {Equations}.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in {Neural} {Information} {Processing}
  {Systems} 31}, pages 6571--6583. Curran Associates, Inc., 2018.

\bibitem{chen_symplectic_2020}
Z.~Chen, J.~Zhang, M.~Arjovsky, and L.~Bottou.
\newblock Symplectic {Recurrent} {Neural} {Networks}.
\newblock {\em arXiv:1909.13334 [cs, stat]}, Apr. 2020.
\newblock arXiv: 1909.13334.

\bibitem{choudhary_physics_2019}
A.~Choudhary, J.~F. Lindner, E.~G. Holliday, S.~T. Miller, S.~Sinha, and W.~L.
  Ditto.
\newblock Physics enhanced neural networks predict order and chaos.
\newblock {\em arXiv:1912.01958 [physics]}, Nov. 2019.
\newblock arXiv: 1912.01958.

\bibitem{cowan_neural_1990}
J.~D. Cowan.
\newblock Neural {Networks}: {The} {Early} {Days}.
\newblock In D.~S. Touretzky, editor, {\em Advances in {Neural} {Information}
  {Processing} {Systems} 2}, pages 828--842. Morgan-Kaufmann, 1990.

\bibitem{cranmer_lagrangian_2020}
M.~Cranmer, S.~Greydanus, S.~Hoyer, P.~Battaglia, D.~Spergel, and S.~Ho.
\newblock Lagrangian {Neural} {Networks}.
\newblock {\em arXiv:2003.04630 [physics, stat]}, Mar. 2020.
\newblock arXiv: 2003.04630.

\bibitem{cranmer_learning_2019}
M.~D. Cranmer, R.~Xu, P.~Battaglia, and S.~Ho.
\newblock Learning {Symbolic} {Physics} with {Graph} {Networks}.
\newblock {\em arXiv:1909.05862 [astro-ph, physics:physics, stat]}, Nov. 2019.
\newblock arXiv: 1909.05862.

\bibitem{devlin_bert_2019}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock {BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for
  {Language} {Understanding}.
\newblock {\em arXiv:1810.04805 [cs]}, May 2019.
\newblock arXiv: 1810.04805.

\bibitem{dupont_augmented_2019}
E.~Dupont, A.~Doucet, and Y.~W. Teh.
\newblock Augmented {Neural} {ODEs}.
\newblock {\em arXiv:1904.01681 [cs, stat]}, Oct. 2019.
\newblock arXiv: 1904.01681.

\bibitem{geist_learning_2020}
A.~R. Geist and S.~Trimpe.
\newblock Learning {Constrained} {Dynamics} with {Gauss} {Principle} adhering
  {Gaussian} {Processes}.
\newblock {\em arXiv:2004.11238 [cs, eess, stat]}, Apr. 2020.
\newblock arXiv: 2004.11238.

\bibitem{greydanus_hamiltonian_2019}
S.~Greydanus, M.~Dzamba, and J.~Yosinski.
\newblock Hamiltonian {Neural} {Networks}.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d. Alché-Buc,
  E.~Fox, and R.~Garnett, editors, {\em Advances in {Neural} {Information}
  {Processing} {Systems} 32}, pages 15379--15389. Curran Associates, Inc.,
  2019.

\bibitem{he_mask_2018}
K.~He, G.~Gkioxari, P.~Dollár, and R.~Girshick.
\newblock Mask {R}-{CNN}.
\newblock {\em arXiv:1703.06870 [cs]}, Jan. 2018.
\newblock arXiv: 1703.06870.

\bibitem{he_deep_2015}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep {Residual} {Learning} for {Image} {Recognition}.
\newblock {\em arXiv:1512.03385 [cs]}, Dec. 2015.
\newblock arXiv: 1512.03385.

\bibitem{hornik_multilayer_1989}
K.~Hornik, M.~Stinchcombe, and H.~White.
\newblock Multilayer feedforward networks are universal approximators.
\newblock {\em Neural Networks}, 2(5):359--366, Jan. 1989.

\bibitem{howse_gradient_1996}
J.~W. Howse, C.~T. Abdallah, and G.~L. Heileman.
\newblock Gradient and {Hamiltonian} {Dynamics} {Applied} to {Learning} in
  {Neural} {Networks}.
\newblock In D.~S. Touretzky, M.~C. Mozer, and M.~E. Hasselmo, editors, {\em
  Advances in {Neural} {Information} {Processing} {Systems} 8}, pages 274--280.
  MIT Press, 1996.

\bibitem{iten_discovering_2020}
R.~Iten, T.~Metger, H.~Wilming, L.~del Rio, and R.~Renner.
\newblock Discovering physical concepts with neural networks.
\newblock {\em Physical Review Letters}, 124(1):010508, Jan. 2020.
\newblock arXiv: 1807.10300.

\bibitem{jin_sympnets_2020}
P.~Jin, Z.~Zhang, A.~Zhu, Y.~Tang, and G.~E. Karniadakis.
\newblock {SympNets}: {Intrinsic} structure-preserving symplectic networks for
  identifying {Hamiltonian} systems.
\newblock {\em Neural Networks}, 132:166--179, Dec. 2020.

\bibitem{lachapelle_gradient-based_2020}
S.~Lachapelle, P.~Brouillard, T.~Deleu, and S.~Lacoste-Julien.
\newblock {GRADIENT}-{BASED} {NEURAL} {DAG} {LEARNING}.
\newblock page~23, 2020.

\bibitem{lamb_graph_2020}
L.~Lamb, A.~Garcez, M.~Gori, M.~Prates, P.~Avelar, and M.~Vardi.
\newblock Graph {Neural} {Networks} {Meet} {Neural}-{Symbolic} {Computing}: {A}
  {Survey} and {Perspective}.
\newblock {\em arXiv:2003.00330 [cs]}, Mar. 2020.
\newblock arXiv: 2003.00330.

\bibitem{lew_overview_nodate}
A.~Lew, J.~E. Marsden, M.~Ortiz, and M.~West.
\newblock {AN} {OVERVIEW} {OF} {VARIATIONAL} {INTEGRATORS}.
\newblock {\em Finite Element Methods}, page~18.

\bibitem{lutter_deep_2019}
M.~Lutter, C.~Ritter, and J.~Peters.
\newblock Deep {Lagrangian} {Networks}: {Using} {Physics} as {Model} {Prior}
  for {Deep} {Learning}.
\newblock {\em arXiv:1907.04490 [cs, eess, stat]}, July 2019.
\newblock arXiv: 1907.04490.

\bibitem{marsden_discrete_2001}
J.~E. Marsden and M.~West.
\newblock Discrete mechanics and variational integrators.
\newblock {\em Acta Numerica}, 10:357--514, May 2001.

\bibitem{pamfil_dynotears_2020}
R.~Pamfil, N.~Sriwattanaworachai, S.~Desai, P.~Pilgerstorfer, P.~Beaumont,
  K.~Georgatzis, and B.~Aragam.
\newblock {DYNOTEARS}: {Structure} {Learning} from {Time}-{Series} {Data}.
\newblock {\em arXiv:2002.00498 [cs, stat]}, Apr. 2020.
\newblock arXiv: 2002.00498.

\bibitem{pukrittayakamee_simultaneous_2009}
A.~Pukrittayakamee, M.~Malshe, M.~Hagan, L.~M. Raff, R.~Narulkar,
  S.~Bukkapatnum, and R.~Komanduri.
\newblock Simultaneous fitting of a potential-energy surface and its
  corresponding force fields using feedforward neural networks.
\newblock {\em The Journal of Chemical Physics}, 130(13):134101, Apr. 2009.

\bibitem{raissi_physics-informed_2019}
M.~Raissi, P.~Perdikaris, and G.~E. Karniadakis.
\newblock Physics-informed neural networks: {A} deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock {\em Journal of Computational Physics}, 378:686--707, Feb. 2019.

\bibitem{rezek_operator_nodate}
I.~Rezek and S.~J. Roberts.
\newblock An {Operator} {Interpretation} of {Message} {Passing}.
\newblock page~8.

\bibitem{rhone_data-driven_2018}
T.~D. Rhone, W.~Chen, S.~Desai, A.~Yacoby, and E.~Kaxiras.
\newblock Data-driven studies of magnetic two-dimensional materials.
\newblock {\em arXiv:1806.07989 [cond-mat]}, June 2018.
\newblock arXiv: 1806.07989.

\bibitem{roehrl_modeling_2020}
M.~A. Roehrl, T.~A. Runkler, V.~Brandtstetter, M.~Tokic, and S.~Obermayer.
\newblock Modeling {System} {Dynamics} with {Physics}-{Informed} {Neural}
  {Networks} {Based} on {Lagrangian} {Mechanics}.
\newblock {\em arXiv:2005.14617 [cs, stat]}, May 2020.
\newblock arXiv: 2005.14617.

\bibitem{rupp_fast_2012}
M.~Rupp, A.~Tkatchenko, K.-R. Müller, and O.~A. von Lilienfeld.
\newblock Fast and {Accurate} {Modeling} of {Molecular} {Atomization}
  {Energies} with {Machine} {Learning}.
\newblock {\em Physical Review Letters}, 108(5):058301, Jan. 2012.
\newblock Publisher: American Physical Society.

\bibitem{saemundsson_variational_2019}
S.~Saemundsson, A.~Terenin, K.~Hofmann, and M.~P. Deisenroth.
\newblock Variational {Integrator} {Networks} for {Physically} {Meaningful}
  {Embeddings}.
\newblock {\em arXiv:1910.09349 [cs, stat]}, Oct. 2019.
\newblock arXiv: 1910.09349.

\bibitem{sanchez-gonzalez_hamiltonian_2019}
A.~Sanchez-Gonzalez, V.~Bapst, K.~Cranmer, and P.~Battaglia.
\newblock Hamiltonian {Graph} {Networks} with {ODE} {Integrators}.
\newblock {\em arXiv:1909.12790 [physics]}, Sept. 2019.
\newblock arXiv: 1909.12790.

\bibitem{sanchez-gonzalez_learning_2020}
A.~Sanchez-Gonzalez, J.~Godwin, T.~Pfaff, R.~Ying, J.~Leskovec, and P.~W.
  Battaglia.
\newblock Learning to {Simulate} {Complex} {Physics} with {Graph} {Networks}.
\newblock {\em arXiv:2002.09405 [physics, stat]}, Feb. 2020.
\newblock arXiv: 2002.09405.

\bibitem{sanchez-gonzalez_graph_2018}
A.~Sanchez-Gonzalez, N.~Heess, J.~T. Springenberg, J.~Merel, M.~Riedmiller,
  R.~Hadsell, and P.~Battaglia.
\newblock Graph networks as learnable physics engines for inference and
  control.
\newblock {\em arXiv:1806.01242 [cs, stat]}, June 2018.
\newblock arXiv: 1806.01242.

\bibitem{seo_differentiable_2019}
S.~Seo and Y.~Liu.
\newblock Differentiable {Physics}-informed {Graph} {Networks}.
\newblock {\em arXiv:1902.02950 [cs, stat]}, Feb. 2019.
\newblock arXiv: 1902.02950.

\bibitem{seo_physics-aware_2020}
S.~Seo, C.~Meng, and Y.~Liu.
\newblock {PHYSICS}-{AWARE} {DIFFERENCE} {GRAPH} {NETWORKS} {FOR}
  {SPARSELY}-{OBSERVED} {DYNAMICS}.
\newblock page~15, 2020.

\bibitem{smith_ani-1_2017}
J.~S. Smith, O.~Isayev, and A.~E. Roitberg.
\newblock {ANI}-1: an extensible neural network potential with {DFT} accuracy
  at force field computational cost.
\newblock {\em Chemical Science}, 8(4):3192--3203, 2017.

\bibitem{toth_hamiltonian_2019}
P.~Toth, D.~J. Rezende, A.~Jaegle, S.~Racanière, A.~Botev, and I.~Higgins.
\newblock Hamiltonian {Generative} {Networks}.
\newblock {\em arXiv:1909.13789 [cs, stat]}, Sept. 2019.
\newblock arXiv: 1909.13789.

\bibitem{toussaint_differentiable_2018}
M.~Toussaint, K.~Allen, K.~Smith, and J.~Tenenbaum.
\newblock Differentiable {Physics} and {Stable} {Modes} for {Tool}-{Use} and
  {Manipulation} {Planning}.
\newblock In {\em Robotics: {Science} and {Systems} {XIV}}. Robotics: Science
  and Systems Foundation, June 2018.

\bibitem{udrescu_symbolic_2020}
S.-M. Udrescu and M.~Tegmark.
\newblock Symbolic {Pregression}: {Discovering} {Physical} {Laws} from {Raw}
  {Distorted} {Video}.
\newblock {\em arXiv:2005.11212 [physics, stat]}, May 2020.
\newblock arXiv: 2005.11212.

\bibitem{wang_machine_2019}
J.~Wang, S.~Olsson, C.~Wehmeyer, A.~Pérez, N.~E. Charron, G.~de~Fabritiis,
  F.~Noé, and C.~Clementi.
\newblock Machine {Learning} of {Coarse}-{Grained} {Molecular} {Dynamics}
  {Force} {Fields}.
\newblock {\em ACS Central Science}, 5(5):755--767, May 2019.
\newblock Publisher: American Chemical Society.

\bibitem{witkoskie_neural_2005}
J.~B. Witkoskie and D.~J. Doren.
\newblock Neural {Network} {Models} of {Potential} {Energy} {Surfaces}:
  {Prototypical} {Examples}.
\newblock {\em Journal of Chemical Theory and Computation}, 1(1):14--23, Jan.
  2005.

\bibitem{yang_enforcing_2019}
Z.~Yang, J.-L. Wu, and H.~Xiao.
\newblock Enforcing {Deterministic} {Constraints} on {Generative} {Adversarial}
  {Networks} for {Emulating} {Physical} {Systems}.
\newblock {\em arXiv:1911.06671 [physics, stat]}, Nov. 2019.
\newblock arXiv: 1911.06671 version: 1.

\bibitem{yao_tensormol-01_2018}
K.~Yao, J.~E. Herr, D.~Toth, R.~Mckintyre, and J.~Parkhill.
\newblock The {TensorMol}-0.1 model chemistry: a neural network augmented with
  long-range physics.
\newblock {\em Chemical Science}, 9(8):2261--2269, 2018.

\bibitem{yu_dag-gnn_nodate}
Y.~Yu, J.~Chen, T.~Gao, and M.~Yu.
\newblock {DAG}-{GNN}: {DAG} {Structure} {Learning} with {Graph} {Neural}
  {Networks}.
\newblock page~10.

\bibitem{zheng_dags_2018}
X.~Zheng, B.~Aragam, P.~Ravikumar, and E.~P. Xing.
\newblock {DAGs} with {NO} {TEARS}: {Continuous} {Optimization} for {Structure}
  {Learning}.
\newblock {\em arXiv:1803.01422 [cs, stat]}, Nov. 2018.
\newblock arXiv: 1803.01422.

\bibitem{zhong_symplectic_2019}
Y.~D. Zhong, B.~Dey, and A.~Chakraborty.
\newblock Symplectic {ODE}-{Net}: {Learning} {Hamiltonian} {Dynamics} with
  {Control}.
\newblock {\em arXiv:1909.12077 [physics, stat]}, Sept. 2019.
\newblock arXiv: 1909.12077.

\bibitem{zhong_unsupervised_2020}
Y.~D. Zhong and N.~E. Leonard.
\newblock Unsupervised {Learning} of {Lagrangian} {Dynamics} from {Images} for
  {Prediction} and {Control}.
\newblock {\em arXiv:2007.01926 [cs, eess, stat]}, July 2020.
\newblock arXiv: 2007.01926.

\bibitem{zhu_deep_2020}
A.~Zhu, P.~Jin, and Y.~Tang.
\newblock Deep {Hamiltonian} networks based on symplectic integrators.
\newblock {\em arXiv:2004.13830 [cs, math]}, Apr. 2020.
\newblock arXiv: 2004.13830.

\end{thebibliography}
