\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{abbrv}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Artificial Intelligence}{2}{section.2}\protected@file@percent }
\citation{battaglia_relational_2018}
\citation{battaglia_relational_2018}
\citation{battaglia_relational_2018}
\citation{battaglia_interaction_2016}
\citation{battaglia_relational_2018}
\citation{sanchez-gonzalez_graph_2018}
\citation{seo_differentiable_2019}
\citation{cranmer_learning_2019}
\citation{seo_physics-aware_2020}
\citation{sanchez-gonzalez_learning_2020}
\citation{lamb_graph_2020}
\citation{cranmer_lagrangian_2020}
\citation{battaglia_relational_2018}
\citation{battaglia_relational_2018}
\@writefile{toc}{\contentsline {section}{\numberline {3}Inductive Biases}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Graph Neural Networks}{3}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Graph attribute updates as presented in \cite  {battaglia_relational_2018}. GNNs carry out a sequence of computations and aggregations at an attribute level to determine the next set of values.\relax }}{3}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gnn}{{1}{3}{Graph attribute updates as presented in \cite {battaglia_relational_2018}. GNNs carry out a sequence of computations and aggregations at an attribute level to determine the next set of values.\relax }{figure.caption.2}{}}
\citation{sanchez-gonzalez_hamiltonian_2019}
\citation{bapst_unveiling_2020}
\citation{sanchez-gonzalez_learning_2020}
\citation{sanchez-gonzalez_learning_2020}
\citation{chen_neural_2018}
\citation{chen_neural_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Integrative Biases}{4}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  ODE Networks \cite  {chen_neural_2018} show that in the continuous time limit, residual networks look like integrated neural networks.\relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig.odenet}{{2}{4}{ODE Networks \cite {chen_neural_2018} show that in the continuous time limit, residual networks look like integrated neural networks.\relax }{figure.caption.3}{}}
\citation{chen_neural_2018}
\citation{zhong_symplectic_2019}
\citation{saemundsson_variational_2019}
\citation{dupont_augmented_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Physics priors}{5}{subsection.3.3}\protected@file@percent }
\citation{witkoskie_neural_2005}
\citation{howse_gradient_1996}
\citation{witkoskie_neural_2005}
\citation{pukrittayakamee_simultaneous_2009}
\citation{smith_ani-1_2017}
\citation{rupp_fast_2012}
\citation{yao_tensormol-01_2018}
\citation{witkoskie_neural_2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Gradient Learning}{6}{subsection.3.4}\protected@file@percent }
\citation{raissi_physics-informed_2019}
\citation{greydanus_hamiltonian_2019}
\citation{greydanus_hamiltonian_2019}
\citation{greydanus_hamiltonian_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Physics Informed Neural Networks}{7}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Energy Conserving Networks}{7}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Hamiltonian Neural Networks}{7}{subsubsection.3.6.1}\protected@file@percent }
\newlabel{HNN}{{3.6.1}{7}{Hamiltonian Neural Networks}{subsubsection.3.6.1}{}}
\citation{greydanus_hamiltonian_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Trajectories of a 2-body system as predicted in \cite  {greydanus_hamiltonian_2019}.\relax }}{8}{figure.caption.4}\protected@file@percent }
\newlabel{eqn.hamiltonian}{{3}{8}{Hamiltonian Neural Networks}{equation.3.3}{}}
\newlabel{eqn.action_int}{{4}{8}{Hamiltonian Neural Networks}{equation.3.4}{}}
\citation{marsden_discrete_2001}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}Deep Lagrangian Network}{9}{subsubsection.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3}Variational Integrator Networks}{9}{subsubsection.3.6.3}\protected@file@percent }
\newlabel{eqn.action_integral}{{9}{9}{Variational Integrator Networks}{equation.3.9}{}}
\citation{saemundsson_variational_2019}
\citation{lew_overview_nodate}
\citation{zhong_unsupervised_2020}
\newlabel{eqn.euler_lagrange}{{10}{10}{Variational Integrator Networks}{equation.3.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.4}Deep Energy Network}{10}{subsubsection.3.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.5}Unsupervised Learning of Lagrangian Dynamics}{10}{subsubsection.3.6.5}\protected@file@percent }
\citation{cranmer_lagrangian_2020}
\citation{roehrl_modeling_2020}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.6}Lagrangian Neural Networks}{11}{subsubsection.3.6.6}\protected@file@percent }
\newlabel{eqn.lnn1}{{13}{11}{Lagrangian Neural Networks}{equation.3.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.7}Modeling System Dynamics with PINNs on Lagrangian Mechanics}{11}{subsubsection.3.6.7}\protected@file@percent }
\citation{zhong_symplectic_2019}
\citation{zhong_symplectic_2019}
\citation{zhong_symplectic_2019}
\citation{chen_symplectic_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Symplectic Integrators from \cite  {zhong_symplectic_2019} show that their capacity at predicting long range trajectories preserve phase-space volume\relax }}{12}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Symplectic Networks}{12}{subsection.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1}Symplectic ODE Net}{12}{subsubsection.3.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.2}Symplectic Recurrent Neural Network}{12}{subsubsection.3.7.2}\protected@file@percent }
\citation{zhu_deep_2020}
\citation{jin_sympnets_2020}
\citation{geist_learning_2020}
\citation{atkinson_bayesian_2020}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.3}Deep Hamiltonian Networks based on symplectic integrators}{13}{subsubsection.3.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.4}SympNets}{13}{subsubsection.3.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Gaussian-Based Physics Networks}{13}{subsection.3.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.8.1}Learning Constrained Dynamics with Gauss' Principle adhering Gaussian Processes}{13}{subsubsection.3.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.8.2}Bayesian Hidden Physics Models}{13}{subsubsection.3.8.2}\protected@file@percent }
\citation{iten_discovering_2020}
\citation{brunton_discovering_2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9}Data Driven Model Discovery}{14}{subsection.3.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.1}Discovering Physical Concepts with Neural Networks}{14}{subsubsection.3.9.1}\protected@file@percent }
\citation{udrescu_symbolic_2020}
\citation{choudhary_physics_2019}
\citation{cranmer_lagrangian_2020}
\citation{rupp_fast_2012}
\citation{witkoskie_neural_2005}
\citation{pukrittayakamee_simultaneous_2009}
\citation{smith_ani-1_2017}
\citation{yao_tensormol-01_2018}
\citation{rupp_fast_2012}
\citation{wang_machine_2019}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.2}Discovering Governing equations from data by sparse identification of nonlinear dynamical systems}{15}{subsubsection.3.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.3}Symbolic Pregression}{15}{subsubsection.3.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10}Physics Informed Neural Network Applications}{15}{subsection.3.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.10.1}Chaos}{15}{subsubsection.3.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.10.2}Materials}{15}{subsubsection.3.10.2}\protected@file@percent }
\citation{zheng_dags_2018}
\citation{pamfil_dynotears_2020}
\citation{lachapelle_gradient-based_2020}
\citation{yu_dag-gnn_nodate}
\bibdata{references.bib}
\bibcite{atkinson_bayesian_2020}{1}
\bibcite{bapst_unveiling_2020}{2}
\bibcite{battaglia_relational_2018}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11}Causality}{16}{subsection.3.11}\protected@file@percent }
\bibcite{battaglia_interaction_2016}{4}
\bibcite{brunton_discovering_2016}{5}
\bibcite{chen_neural_2018}{6}
\bibcite{chen_symplectic_2020}{7}
\bibcite{choudhary_physics_2019}{8}
\bibcite{cranmer_lagrangian_2020}{9}
\bibcite{cranmer_learning_2019}{10}
\bibcite{dupont_augmented_2019}{11}
\bibcite{geist_learning_2020}{12}
\bibcite{greydanus_hamiltonian_2019}{13}
\bibcite{howse_gradient_1996}{14}
\bibcite{iten_discovering_2020}{15}
\bibcite{jin_sympnets_2020}{16}
\bibcite{lachapelle_gradient-based_2020}{17}
\bibcite{lamb_graph_2020}{18}
\bibcite{lew_overview_nodate}{19}
\bibcite{marsden_discrete_2001}{20}
\bibcite{pamfil_dynotears_2020}{21}
\bibcite{pukrittayakamee_simultaneous_2009}{22}
\bibcite{raissi_physics-informed_2019}{23}
\bibcite{roehrl_modeling_2020}{24}
\bibcite{rupp_fast_2012}{25}
\bibcite{saemundsson_variational_2019}{26}
\bibcite{sanchez-gonzalez_hamiltonian_2019}{27}
\bibcite{sanchez-gonzalez_learning_2020}{28}
\bibcite{sanchez-gonzalez_graph_2018}{29}
\bibcite{seo_differentiable_2019}{30}
\bibcite{seo_physics-aware_2020}{31}
\bibcite{smith_ani-1_2017}{32}
\bibcite{udrescu_symbolic_2020}{33}
\bibcite{wang_machine_2019}{34}
\bibcite{witkoskie_neural_2005}{35}
\bibcite{yao_tensormol-01_2018}{36}
\bibcite{yu_dag-gnn_nodate}{37}
\bibcite{zheng_dags_2018}{38}
\bibcite{zhong_symplectic_2019}{39}
\bibcite{zhong_unsupervised_2020}{40}
\bibcite{zhu_deep_2020}{41}
