\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{abbrv}
\citation{cowan_neural_1990}
\citation{cowan_neural_1990}
\citation{hornik_multilayer_1989}
\citation{he_mask_2018}
\citation{devlin_bert_2019}
\citation{toussaint_differentiable_2018}
\citation{battaglia_relational_2018}
\citation{battaglia_relational_2018}
\citation{battaglia_relational_2018}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Inductive Biases}{3}{section.2}\protected@file@percent }
\citation{battaglia_relational_2018}
\citation{battaglia_interaction_2016}
\citation{battaglia_relational_2018}
\citation{sanchez-gonzalez_graph_2018}
\citation{seo_differentiable_2019}
\citation{cranmer_learning_2019}
\citation{seo_physics-aware_2020}
\citation{sanchez-gonzalez_learning_2020}
\citation{lamb_graph_2020}
\citation{cranmer_lagrangian_2020}
\citation{battaglia_relational_2018}
\citation{sanchez-gonzalez_hamiltonian_2019}
\citation{bapst_unveiling_2020}
\citation{sanchez-gonzalez_learning_2020}
\citation{sanchez-gonzalez_learning_2020}
\citation{rezek_operator_nodate}
\citation{battaglia_relational_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Graph Neural Networks}{4}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Graph attribute updates as presented in \cite  {battaglia_relational_2018}. GNNs carry out a sequence of computations and aggregations at an attribute level to determine the next set of values.\relax }}{4}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gnn}{{1}{4}{Graph attribute updates as presented in \cite {battaglia_relational_2018}. GNNs carry out a sequence of computations and aggregations at an attribute level to determine the next set of values.\relax }{figure.caption.2}{}}
\citation{chen_neural_2018}
\citation{chen_neural_2018}
\citation{chang_reversible_2017}
\citation{chen_neural_2018}
\citation{he_deep_2015}
\citation{chen_neural_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Integrative Biases}{5}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  ODE Networks \cite  {chen_neural_2018} show that in the continuous time limit, residual networks look like integrated neural networks.\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig.odenet}{{2}{5}{ODE Networks \cite {chen_neural_2018} show that in the continuous time limit, residual networks look like integrated neural networks.\relax }{figure.caption.3}{}}
\newlabel{eqn.odedisc}{{1}{5}{Integrative Biases}{equation.2.1}{}}
\citation{zhong_symplectic_2019}
\citation{saemundsson_variational_2019}
\citation{dupont_augmented_2019}
\citation{rupp_fast_2012}
\citation{smith_ani-1_2017}
\citation{rhone_data-driven_2018}
\citation{battaglia_relational_2018}
\citation{bapst_unveiling_2020}
\citation{witkoskie_neural_2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Physics priors}{6}{subsection.2.3}\protected@file@percent }
\citation{howse_gradient_1996}
\citation{witkoskie_neural_2005}
\citation{pukrittayakamee_simultaneous_2009}
\citation{smith_ani-1_2017}
\citation{rupp_fast_2012}
\citation{yao_tensormol-01_2018}
\citation{witkoskie_neural_2005}
\citation{howse_gradient_1996}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Gradient Learning}{7}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}PINNs: Physics Informed Neural Networks}{7}{subsection.2.5}\protected@file@percent }
\citation{raissi_physics-informed_2019}
\citation{greydanus_hamiltonian_2019}
\citation{greydanus_hamiltonian_2019}
\citation{greydanus_hamiltonian_2019}
\citation{greydanus_hamiltonian_2019}
\citation{raissi_physics-informed_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Energy Conserving Networks}{8}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}Hamiltonian Neural Networks}{8}{subsubsection.2.6.1}\protected@file@percent }
\newlabel{HNN}{{2.6.1}{8}{Hamiltonian Neural Networks}{subsubsection.2.6.1}{}}
\newlabel{eqn.hamiltonian}{{4}{8}{Hamiltonian Neural Networks}{equation.2.4}{}}
\citation{marsden_discrete_2001}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Trajectories of a 2-body system as predicted in \cite  {greydanus_hamiltonian_2019}.\relax }}{9}{figure.caption.4}\protected@file@percent }
\newlabel{eqn.action_int}{{5}{9}{Hamiltonian Neural Networks}{equation.2.5}{}}
\citation{saemundsson_variational_2019}
\citation{lew_overview_nodate}
\citation{lutter_deep_2019}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2}Variational Integrator Networks}{10}{subsubsection.2.6.2}\protected@file@percent }
\newlabel{eqn.action_integral}{{6}{10}{Variational Integrator Networks}{equation.2.6}{}}
\newlabel{eqn.euler_lagrange}{{7}{10}{Variational Integrator Networks}{equation.2.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.3}Deep Lagrangian Network}{10}{subsubsection.2.6.3}\protected@file@percent }
\citation{cranmer_lagrangian_2020}
\citation{zhong_unsupervised_2020}
\citation{cranmer_lagrangian_2020}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.4}Unsupervised Learning of Lagrangian Dynamics}{11}{subsubsection.2.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.5}Lagrangian Neural Networks}{11}{subsubsection.2.6.5}\protected@file@percent }
\citation{roehrl_modeling_2020}
\citation{zhu_deep_2020}
\newlabel{eqn.lnn1}{{12}{12}{Lagrangian Neural Networks}{equation.2.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.6}Modeling System Dynamics with PINNs on Lagrangian Mechanics}{12}{subsubsection.2.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Symplectic Networks}{12}{subsection.2.7}\protected@file@percent }
\citation{zhong_symplectic_2019}
\citation{zhong_symplectic_2019}
\citation{zhong_symplectic_2019}
\citation{zhong_symplectic_2019}
\citation{chen_symplectic_2020}
\citation{zhu_deep_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Symplectic Integrators from \cite  {zhong_symplectic_2019} illustrate their improved capacity over non-symplectic integrators at predicting long range trajectories that preserve phase-space volume.\relax }}{13}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.1}Symplectic ODE Net}{13}{subsubsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.2}Symplectic Recurrent Neural Network}{13}{subsubsection.2.7.2}\protected@file@percent }
\citation{jin_sympnets_2020}
\citation{geist_learning_2020}
\citation{atkinson_bayesian_2020}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.3}Deep Hamiltonian Networks based on symplectic integrators}{14}{subsubsection.2.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.4}SympNets}{14}{subsubsection.2.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Gaussian-Based Physics Networks}{14}{subsection.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.1}Learning Constrained Dynamics with Gauss' Principle adhering Gaussian Processes}{14}{subsubsection.2.8.1}\protected@file@percent }
\citation{iten_discovering_2020}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2}Bayesian Hidden Physics Models}{15}{subsubsection.2.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Data Driven Model Discovery}{15}{subsection.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.1}Discovering Physical Concepts with Neural Networks}{15}{subsubsection.2.9.1}\protected@file@percent }
\citation{brunton_discovering_2016}
\citation{udrescu_symbolic_2020}
\citation{yang_enforcing_2019}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.2}Discovering Governing equations from data by sparse identification of nonlinear dynamical systems}{16}{subsubsection.2.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.3}Symbolic Pregression}{16}{subsubsection.2.9.3}\protected@file@percent }
\citation{choudhary_physics_2019}
\citation{cranmer_lagrangian_2020}
\citation{rupp_fast_2012}
\citation{witkoskie_neural_2005}
\citation{pukrittayakamee_simultaneous_2009}
\citation{smith_ani-1_2017}
\citation{yao_tensormol-01_2018}
\citation{rupp_fast_2012}
\citation{wang_machine_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10}Physics Informed Generative Adversarial Networks}{17}{subsection.2.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11}Physics Informed Neural Network Applications}{17}{subsection.2.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.11.1}Chaos}{17}{subsubsection.2.11.1}\protected@file@percent }
\citation{zheng_dags_2018}
\citation{pamfil_dynotears_2020}
\citation{lachapelle_gradient-based_2020}
\citation{yu_dag-gnn_nodate}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.11.2}Materials}{18}{subsubsection.2.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.12}Causality}{18}{subsection.2.12}\protected@file@percent }
\citation{greydanus_hamiltonian_2019}
\citation{toth_hamiltonian_2019}
\citation{udrescu_symbolic_2020}
\citation{iten_discovering_2020}
\citation{brunton_discovering_2016}
\citation{sanchez-gonzalez_hamiltonian_2019}
\citation{lutter_deep_2019}
\citation{zhong_symplectic_2019}
\citation{greydanus_hamiltonian_2019}
\@writefile{toc}{\contentsline {section}{\numberline {3}Research Proposal}{19}{section.3}\protected@file@percent }
\bibdata{references.bib}
\bibcite{atkinson_bayesian_2020}{1}
\bibcite{bapst_unveiling_2020}{2}
\bibcite{battaglia_relational_2018}{3}
\bibcite{battaglia_interaction_2016}{4}
\bibcite{brunton_discovering_2016}{5}
\bibcite{chang_reversible_2017}{6}
\bibcite{chen_neural_2018}{7}
\bibcite{chen_symplectic_2020}{8}
\bibcite{choudhary_physics_2019}{9}
\bibcite{cowan_neural_1990}{10}
\bibcite{cranmer_lagrangian_2020}{11}
\bibcite{cranmer_learning_2019}{12}
\bibcite{devlin_bert_2019}{13}
\bibcite{dupont_augmented_2019}{14}
\bibcite{geist_learning_2020}{15}
\bibcite{greydanus_hamiltonian_2019}{16}
\bibcite{he_mask_2018}{17}
\bibcite{he_deep_2015}{18}
\bibcite{hornik_multilayer_1989}{19}
\bibcite{howse_gradient_1996}{20}
\bibcite{iten_discovering_2020}{21}
\bibcite{jin_sympnets_2020}{22}
\bibcite{lachapelle_gradient-based_2020}{23}
\bibcite{lamb_graph_2020}{24}
\bibcite{lew_overview_nodate}{25}
\bibcite{lutter_deep_2019}{26}
\bibcite{marsden_discrete_2001}{27}
\bibcite{pamfil_dynotears_2020}{28}
\bibcite{pukrittayakamee_simultaneous_2009}{29}
\bibcite{raissi_physics-informed_2019}{30}
\bibcite{rezek_operator_nodate}{31}
\bibcite{rhone_data-driven_2018}{32}
\bibcite{roehrl_modeling_2020}{33}
\bibcite{rupp_fast_2012}{34}
\bibcite{saemundsson_variational_2019}{35}
\bibcite{sanchez-gonzalez_hamiltonian_2019}{36}
\bibcite{sanchez-gonzalez_learning_2020}{37}
\bibcite{sanchez-gonzalez_graph_2018}{38}
\bibcite{seo_differentiable_2019}{39}
\bibcite{seo_physics-aware_2020}{40}
\bibcite{smith_ani-1_2017}{41}
\bibcite{toussaint_differentiable_2018}{42}
\bibcite{udrescu_symbolic_2020}{43}
\bibcite{wang_machine_2019}{44}
\bibcite{witkoskie_neural_2005}{45}
\bibcite{yang_enforcing_2019}{46}
\bibcite{yao_tensormol-01_2018}{47}
\bibcite{yu_dag-gnn_nodate}{48}
\bibcite{zheng_dags_2018}{49}
\bibcite{zhong_symplectic_2019}{50}
\bibcite{zhong_unsupervised_2020}{51}
\bibcite{zhu_deep_2020}{52}
